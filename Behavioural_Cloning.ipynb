{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Behavioural_Cloning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBqAwTRUoOFD"
      },
      "source": [
        "!git clone https://github.com/jaimin-k/Usim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXH6gr-aonOh"
      },
      "source": [
        "!ls Usim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eyCx7NlO7Nd"
      },
      "source": [
        "!pip install keras\n",
        "!pip3 install imgaug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw5rSyIYdXcM"
      },
      "source": [
        "!pip3 install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfI8fgkxovJ3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical \n",
        "\n",
        "from keras.layers import Dropout,Flatten\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imgaug import augmenters as iaa\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import ntpath\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y25mHZVgpCjd"
      },
      "source": [
        "Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-b0E0FhpCBn"
      },
      "source": [
        "datadir = 'Usim'\n",
        "columns = ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']\n",
        "data = pd.read_csv(os.path.join(datadir, 'driving_log.csv'), names = columns)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "data.head()\n",
        "def path_leaf(path):\n",
        "  head, tail = ntpath.split(path)\n",
        "  return tail\n",
        "data['center'] = data['center'].apply(path_leaf)\n",
        "data['left'] = data['left'].apply(path_leaf)\n",
        "data['right'] = data['right'].apply(path_leaf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnoJodedqWG2"
      },
      "source": [
        "def path_leaf(path):\n",
        "  head,tail = ntpath.split(path)\n",
        "  return tail\n",
        "data['center']=data['center'].apply(path_leaf)\n",
        "data['left']=data['left'].apply(path_leaf)\n",
        "data['right']=data['right'].apply(path_leaf)\n",
        "#data.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hRAD5PLrPkc"
      },
      "source": [
        "Construct histogram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dxeJP6R4MNT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ_fO1U2rPQy"
      },
      "source": [
        "num_bins = 26\n",
        "samples_per_bin = 690\n",
        "hist, bins = np.histogram(data['steering'], num_bins)\n",
        "center = (bins[:-1]+ bins[1:]) * 0.5\n",
        "plt.bar(center, hist, width=0.05)\n",
        "plt.plot((np.min(data['steering']), np.max(data['steering'])), (samples_per_bin, samples_per_bin))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVXG-PLSury6"
      },
      "source": [
        "flatten extraneous samples for specific bins whose freq. exceed 200 #preprocessing\n",
        "making distribution more uniform further"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UL2KZXZu5T0"
      },
      "source": [
        "print(\"total data\",len(data))\n",
        "remove_list =[]\n",
        "#looping through samples of each bin\n",
        "for j in range(num_bins):\n",
        "  list_=[]\n",
        "  for i in range(len(data['steering'])):\n",
        "    if data['steering'][i]>= bins[j] and data['steering'][i] <= bins[j+1]: #if ssteering angle falls between two bins eg -0.72,-0.69 will all belong to same bin\n",
        "    #append each index that fall in specifc category in the list\n",
        "      list_.append(i)\n",
        "  list_ = shuffle(list_)\n",
        "  list_ = list_[samples_per_bin:]\n",
        "  remove_list.extend(list_)\n",
        "\n",
        "print('removed',len(remove_list))\n",
        "data.drop(data.index[remove_list],inplace=True)\n",
        "print('remaining',len(data))\n",
        "\n",
        "hist,_ = np.histogram(data['steering'],(num_bins))\n",
        "plt.bar(center,hist, width=0.05)\n",
        "plt.plot((np.min(data['steering']),np.max(data['steering'])),(samples_per_bin,samples_per_bin))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvV-T7wSyfSC"
      },
      "source": [
        "traing data corresponding steering angles as labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq1LjRjyyeoG"
      },
      "source": [
        "print(data.iloc[1])\n",
        "def load_img_steering(datadir,df):\n",
        "  image_path=[]\n",
        "  steering=[]\n",
        "  for i in range(len(data)):\n",
        "    indexed_data = data.iloc[i] #iloc allows to perform selection of data from dataframe based on specified angle, index data will contain specific row of data of each iteration\n",
        "    center,left,right = indexed_data[0], indexed_data[1],indexed_data[2]\n",
        "    image_path.append(os.path.join(datadir, center.strip())) #gives specific path for each image\n",
        "    steering.append(float(indexed_data[3]))\n",
        "  image_paths = np.asarray(image_path)\n",
        "  steerings = np.asarray(steering)\n",
        "  return image_path, steerings\n",
        "image_paths,steerings =  load_img_steering(datadir + '/IMG', data) #2 arrays-one for images and other with each images corresponding label-steering angle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EYuXkDs1p89"
      },
      "source": [
        "**Split data collected from simulation into training and validation data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GddfyJHQ1M7f"
      },
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(image_paths, steerings, test_size= 0.2 , random_state=0)\n",
        "print(f'Training Samples={len(X_train)}, Validation Samples= {len(X_val)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtAN5_jl2i0f"
      },
      "source": [
        "fig, axes = plt.subplots(1,2,figsize=(12,4))\n",
        "axes[0].hist(y_train, bins=num_bins, width = 0.05 , color = 'blue')\n",
        "axes[0].set_title('Training set')\n",
        "axes[1].hist(y_val, bins=num_bins, width = 0.05 , color = 'red')\n",
        "axes[1].set_title('Validation set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ZyGCJrdne2"
      },
      "source": [
        "#Data augmentation-zooming-to get a closer look at some features in image\n",
        "def zoom(image):\n",
        "  zoom = iaa.Affine(scale=(1,1.3))\n",
        "  image = zoom.augment_image(image)\n",
        "  return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eydgl5RQePHP"
      },
      "source": [
        "image = image_paths[random.randint(0,1000)]\n",
        "original_image = mpimg.imread(image)\n",
        "zoomed_image = zoom(original_image)\n",
        "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
        "fig.tight_layout()\n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original image')\n",
        "\n",
        "axs[1].imshow(zoomed_image)\n",
        "axs[1].set_title('zoomed image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqM9G-TcfGzO"
      },
      "source": [
        "def pan(image):\n",
        "  pan = iaa.Affine(translate_percent={'x':(-0.1,0.1),'y':(-0.1,0.1)})#appine decides random percentage of pan\n",
        "  image = pan.augment_image(image)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY9P37OEv-JN"
      },
      "source": [
        "\n",
        "#image = image_paths[random.randint(0,1000)]\n",
        "#original_image = mpimg.imread(image)\n",
        "#panned_image = pan(original_image)\n",
        "#fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
        "#fig.tight_layout()\n",
        "#axs[0].imshow(original_image)\n",
        "#axs[0].set_title('Original image')\n",
        "\n",
        "#axs[1].imshow(panned_image)\n",
        "#axs[1].set_title('panned image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmzS2EJBf9Hd"
      },
      "source": [
        "image = image_paths[random.randint(0,1000)]\n",
        "original_image = mpimg.imread(image)\n",
        "panned_image = pan(original_image)\n",
        "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
        "fig.tight_layout()\n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original image')\n",
        "\n",
        "axs[1].imshow(panned_image)\n",
        "axs[1].set_title('panned image')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9XhWKqLhZtv"
      },
      "source": [
        "def img_random_brightness(image):\n",
        "  brightness = iaa.Multiply((0.2,1.2))\n",
        "  image = brightness.augment_image(image)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2WDHxJEhsU1"
      },
      "source": [
        "image = image_paths[random.randint(0,1000)]\n",
        "original_image = mpimg.imread(image)\n",
        "Brighteness_altered_image = img_random_brightness(original_image)\n",
        "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
        "fig.tight_layout()\n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original image')\n",
        "\n",
        "axs[1].imshow(Brighteness_altered_image)\n",
        "axs[1].set_title('Brighteness altered image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOKrgaTyivEa"
      },
      "source": [
        "def img_random_flip(image, steering_angle):\n",
        "  image = cv2.flip(image,1 )#0-vertical slip 1:horizontal flip -1:hor,vert flip, \n",
        "  #also need to flip sterring angle\n",
        "  steering_angle = -steering_angle\n",
        "  return image, steering_angle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcpVUCMejT-P"
      },
      "source": [
        "random_index = random.randint(0,1000)\n",
        "image = image_paths[random_index]\n",
        "steering_angle = steerings[random_index]\n",
        "original_image = mpimg.imread(image)\n",
        "flipped_image, flipped_steering_angle = img_random_flip(original_image, steering_angle)\n",
        "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
        "fig.tight_layout()\n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original image-'+'Steering angle:' +str(steering_angle))\n",
        "\n",
        "axs[1].imshow(flipped_image)\n",
        "axs[1].set_title('flipped_image-'+'Steering angle:' +str(flipped_steering_angle))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_f0q8zhmlcn"
      },
      "source": [
        "randomizing occurance of augmentation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxGYPrA7lIOf"
      },
      "source": [
        "def random_augment(image, steering_angle):\n",
        "  image= mpimg.imread(image)\n",
        "  if np.random.rand()<0.5:   #random func returns value between 0 - 1 with 0.5 ie equal probaility we are effectively running this if state. 50 % times\n",
        "    image = pan(image) #pan augmentation applied only 50% of time\n",
        "  if np.random.rand()<0.5:\n",
        "    image = zoom(image)\n",
        "  if np.random.rand()<0.5:\n",
        "    image = img_random_brightness(image)\n",
        "  if np.random.rand()<0.5:\n",
        "    image, steering_angle = img_random_flip(image,steering_angle)  \n",
        "  return image,steering_angle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZhAoCoTmpxJ"
      },
      "source": [
        "plotting fully augmented images with combined augmentation techniqyues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SKe6HDCzmvX7"
      },
      "source": [
        "ncol = 2\n",
        "nrow = 10\n",
        "fig, axs = plt.subplots(nrow,ncol,figsize=(15,50))\n",
        "fig.tight_layout()\n",
        "for i in range(10): #each iteration random image is used to augment\n",
        "  rand_num= random.randint(0,len(image_paths)-1)\n",
        "  random_image = image_paths[rand_num]\n",
        "  random_steering = steerings[rand_num]\n",
        "\n",
        "  original_image = mpimg.imread(random_image)\n",
        "  augmented_image,steering = random_augment(random_image, random_steering)\n",
        "\n",
        "  axs[i][0].imshow(original_image)\n",
        "  axs[i][0].set_title('Original image')\n",
        "\n",
        "  axs[i][1].imshow(augmented_image)\n",
        "  axs[i][1].set_title('Augmented image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2sZSJAI33PL"
      },
      "source": [
        "Preprocessing image data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hBT1tJr36pz"
      },
      "source": [
        "def img_preprocessing(img):\n",
        "  #read image path snd store actial image that it contains\n",
        "  img[60:135,:,:] #cropping height of image roi\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_RGB2YUV)\n",
        "  img = cv2.GaussianBlur(img, (3,3),0)\n",
        "  img = cv2.resize(img, (200,66)) #not necessary but helps to maintain consistent to make image size small and also matches input image size used by NVIDIA model architecture\n",
        "  img = img/255 #normalization (no visual impact on image)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzM8ouI94YPK"
      },
      "source": [
        "image = image_paths[100]\n",
        "original_image = mpimg.imread(image)\n",
        "preprocessed_image = img_preprocessing(original_image)\n",
        "\n",
        "fig, axes = plt.subplots(1,2, figsize=(15,10))\n",
        "fig.tight_layout()\n",
        "axes[0].imshow(original_image)\n",
        "axes[0].set_title('original image')\n",
        "axes[1].imshow(preprocessed_image)\n",
        "axes[1].set_title('preprocessed image')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHzJvBWkyMM8"
      },
      "source": [
        "def batch_generator(image_paths, steering_ang, batch_size, istraining):\n",
        "  \n",
        "  while True:\n",
        "    batch_img = []\n",
        "    batch_steering = []\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "      random_index = random.randint(0, len(image_paths) - 1)\n",
        "      \n",
        "      if istraining:\n",
        "        im, steering = random_augment(image_paths[random_index], steering_ang[random_index])\n",
        "     \n",
        "      else:\n",
        "        im = mpimg.imread(image_paths[random_index])\n",
        "        steering = steering_ang[random_index]\n",
        "      \n",
        "      im = img_preprocessing(im)\n",
        "      batch_img.append(im)\n",
        "      batch_steering.append(steering)\n",
        "    yield (np.asarray(batch_img), np.asarray(batch_steering))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66cgpXWeypHR"
      },
      "source": [
        "X_train_gen,y_train_gen = next(batch_generator(X_train,y_train,1,1))\n",
        "X_val_gen,y_val_gen = next(batch_generator(X_val,y_val,1,0))\n",
        "\n",
        "fig, axes = plt.subplots(1,2, figsize=(15,10))\n",
        "fig.tight_layout()\n",
        "axes[0].imshow(X_train_gen[0])\n",
        "axes[0].set_title('Training image')\n",
        "axes[1].imshow(X_val_gen[0])\n",
        "axes[1].set_title('Validation image')\n",
        "\n",
        "#validating imgs that are not augmented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbP7XaoD7IeA"
      },
      "source": [
        "Running dataset through preprocessing:training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ETBcQmOt7OWD"
      },
      "source": [
        "#X_train = np.array(list(map(img_preprocessing, X_train)))#returns in form of list need to store as an array\n",
        "#X_val = np.array(list(map(img_preprocessing, X_val)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GBk3bGH7syU"
      },
      "source": [
        "#to verify preprocessing successfuully"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BlMTFHLC7uAB"
      },
      "source": [
        "#plt.imshow(X_train[random.randint(0,len(X_train)-1)])\n",
        "#plt.axis('off')\n",
        "#print(X_train.shape,X_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhNNtbc2uyrq"
      },
      "source": [
        "def nvidia_model():    \n",
        "    model= Sequential()\n",
        "     \n",
        "    model.add(Convolution2D(24, (5, 5), (2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(Convolution2D(36, (5, 5), (2, 2), activation='elu'))\n",
        "    \n",
        "    model.add(Convolution2D(48, (5, 5), (2, 2), activation='elu'))\n",
        "    #model.add(Dropout(0.1))\n",
        "    model.add(Convolution2D(64, (3, 3), activation='elu'))\n",
        "    #we replaced it with sigmoid  to avoid vanishing gradient problem in nnet, relu can sometime cause dead relu where nn dies and on returns zero ie if value fed in relu is less than zer o relu passes zero if gradient is zero backpropogation won't update weight and model becomes stagnant and alwas returns zero\n",
        "    #we can replace relu with elu -has non zero gradient vlaue in negative region,it always remain capable of learning and capable of reducing erroe in model\n",
        "    model.add(Convolution2D(64, (3, 3), activation='elu'))\n",
        "    #model.add(Dropout(0.5))\n",
        "  \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(100, activation = 'elu'))\n",
        "    \n",
        "  \n",
        "    model.add(Dense(50, activation = 'elu'))\n",
        "    \n",
        "  \n",
        "    model.add(Dense(10, activation = 'elu'))\n",
        "    \n",
        "  \n",
        "    model.add(Dense(1)) # output the predicted steering angle \n",
        "\n",
        "    optimizer = Adam(lr=0.001)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "model = nvidia_model()    \n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLBXtldj0aFV"
      },
      "source": [
        "history = model.fit_generator(batch_generator(X_train,y_train,batch_size=100, istraining=1), \n",
        "                              steps_per_epoch=150, \n",
        "                              epochs = 20, \n",
        "                              validation_data=batch_generator(X_val,y_val,100,0),\n",
        "                              validation_steps=200,\n",
        "                              verbose=1,\n",
        "                              shuffle=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BElin0J_C6uZ"
      },
      "source": [
        "in final report can show differnce in loss and accuracy comparing relu and elu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NtBIQ2Q8N4P"
      },
      "source": [
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('loss')\n",
        "plt.xlabel('epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_gjYJufB3FY"
      },
      "source": [
        "model.save('model.h5')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfdzDmI4PRrz"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}